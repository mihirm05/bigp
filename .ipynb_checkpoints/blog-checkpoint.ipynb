{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponentiated_quadratic(xa, xb):\n",
    "    sq_norm = -0.5*scipy.spatial.distance.cdist(xa, xb, 'sqeuclidean')\n",
    "    return np.exp(sq_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Illustrate covariance matrix and function\n",
    "\n",
    "# Show covariance matrix example from exponentiated quadratic\n",
    "#fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(7, 3))\n",
    "xlim = (-3, 3)\n",
    "X = np.expand_dims(np.linspace(*xlim, 25), 1)\n",
    "Σ = exponentiated_quadratic(X, X)\n",
    "# Plot covariance matrix\n",
    "#im = ax1.imshow(Σ, cmap=cm.YlGnBu)\n",
    "#cbar = plt.colorbar(\n",
    "#    im, ax=ax1, fraction=0.045, pad=0.05)\n",
    "#cbar.ax.set_ylabel('$k(x,x)$', fontsize=10)\n",
    "#ax1.set_title((\n",
    "#    'Exponentiated quadratic \\n'\n",
    "#    'example of covariance matrix'))\n",
    "#ax1.set_xlabel('x', fontsize=13)\n",
    "#ax1.set_ylabel('x', fontsize=13)\n",
    "#ticks = list(range(xlim[0], xlim[1]+1))\n",
    "#ax1.set_xticks(np.linspace(0, len(X)-1, len(ticks)))\n",
    "#ax1.set_yticks(np.linspace(0, len(X)-1, len(ticks)))\n",
    "#ax1.set_xticklabels(ticks)\n",
    "#ax1.set_yticklabels(ticks)\n",
    "#ax1.grid(False)\n",
    "\n",
    "# Show covariance with X=0\n",
    "xlim = (-4, 4)\n",
    "X = np.expand_dims(np.linspace(*xlim, num=100), 1)\n",
    "zero = np.array([[0]])\n",
    "Σ0 = exponentiated_quadratic(X, zero)\n",
    "# Make the plots\n",
    "#ax2.plot(X[:,0], Σ0[:,0], label='$k(x,0)$')\n",
    "#ax2.set_xlabel('x', fontsize=13)\n",
    "#ax2.set_ylabel('covariance', fontsize=13)\n",
    "#ax2.set_title((\n",
    "    #'Exponentiated quadratic  covariance\\n'\n",
    "    #'between $x$ and $0$'))\n",
    "# ax2.set_ylim([0, 1.1])\n",
    "#ax2.set_xlim(*xlim)\n",
    "#ax2.legend(loc=1)\n",
    "\n",
    "#fig.tight_layout()\n",
    "#plt.show()\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample from the Gaussian process distribution\n",
    "nb_of_samples = 41  # Number of points in each function\n",
    "number_of_functions = 5  # Number of functions to sample\n",
    "# Independent variable samples\n",
    "X = np.expand_dims(np.linspace(-4, 4, nb_of_samples), 1)\n",
    "Σ = exponentiated_quadratic(X, X)  # Kernel of data points\n",
    "\n",
    "# Draw samples from the prior at our data points.\n",
    "# Assume a mean of 0 for simplicity\n",
    "ys = np.random.multivariate_normal(\n",
    "    mean=np.zeros(nb_of_samples), cov=Σ, \n",
    "    size=number_of_functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "for i in range(number_of_functions):\n",
    "    plt.plot(X, ys[i], linestyle='-', marker='o', markersize=3)\n",
    "plt.xlabel('$x$', fontsize=13)\n",
    "plt.ylabel('$y = f(x)$', fontsize=13)\n",
    "plt.title((\n",
    "    '5 different function realizations at 41 points\\n'\n",
    "    'sampled from a Gaussian process with exponentiated quadratic kernel'))\n",
    "plt.xlim([-4, 4])\n",
    "plt.show()\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian process posterior\n",
    "def GP(X1, y1, X2, kernel_func):\n",
    "    \"\"\"\n",
    "    Calculate the posterior mean and covariance matrix for y2\n",
    "    based on the corresponding input X2, the observations (y1, X1), \n",
    "    and the prior kernel function.\n",
    "    \"\"\"\n",
    "    # Kernel of the observations\n",
    "    Σ11 = kernel_func(X1, X1)\n",
    "    # Kernel of observations vs to-predict\n",
    "    Σ12 = kernel_func(X1, X2)\n",
    "    # Solve\n",
    "    solved = scipy.linalg.solve(Σ11, Σ12, assume_a='pos').T\n",
    "    # Compute posterior mean\n",
    "    μ2 = solved @ y1\n",
    "    # Compute the posterior covariance\n",
    "    Σ22 = kernel_func(X2, X2)\n",
    "    Σ2 = Σ22 - (solved @ Σ12)\n",
    "    return μ2, Σ2  # mean, covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the posterior mean and covariance\n",
    "\n",
    "# Define the true function that we want to regress on\n",
    "f_sin = lambda x: (np.sin(x)).flatten()\n",
    "\n",
    "n1 = 8  # Number of points to condition on (training points)\n",
    "n2 = 75  # Number of points in posterior (test points)\n",
    "ny = 5  # Number of functions that will be sampled from the posterior\n",
    "domain = (-6, 6)\n",
    "\n",
    "# Sample observations (X1, y1) on the function\n",
    "X1 = np.random.uniform(domain[0]+2, domain[1]-2, size=(n1,1))\n",
    "y1 = f_sin(X1)\n",
    "# Predict points at uniform spacing to capture function\n",
    "X2 = np.linspace(domain[0], domain[1], n2).reshape(-1,1)\n",
    "# Compute posterior mean and covariance\n",
    "μ2, Σ2 = GP(X1, y1, X2, exponentiated_quadratic)\n",
    "# Compute the standard deviation at the test points to be plotted\n",
    "σ2 = np.sqrt(np.diag(Σ2))\n",
    "\n",
    "# Draw some samples of the posterior\n",
    "y2 = np.random.multivariate_normal(mean=μ2, cov=Σ2, size=ny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the postior distribution and some samples\n",
    "fig, (ax1, ax2) = plt.subplots(\n",
    "    nrows=2, ncols=1, figsize=(6, 6))\n",
    "# Plot the distribution of the function (mean, covariance)\n",
    "#ax1.plot(X2, f_sin(X2), 'b--', label='$sin(x)$')\n",
    "ax1.fill_between(X2.flat, μ2-2*σ2, μ2+2*σ2, color='red', \n",
    "                 alpha=0.15, label='$2 \\sigma_{2|1}$')\n",
    "ax1.plot(X2, μ2, 'r-', lw=2, label='$\\mu_{2|1}$')\n",
    "ax1.plot(X1, y1, 'ko', linewidth=2, label='$(x_1, y_1)$')\n",
    "ax1.set_xlabel('$x$', fontsize=13)\n",
    "ax1.set_ylabel('$y$', fontsize=13)\n",
    "ax1.set_title('Distribution of posterior and prior data.')\n",
    "ax1.axis([domain[0], domain[1], -3, 3])\n",
    "ax1.legend()\n",
    "# Plot some samples from this function\n",
    "ax2.plot(X2, y2.T, '-')\n",
    "ax2.set_xlabel('$x$', fontsize=13)\n",
    "ax2.set_ylabel('$y$', fontsize=13)\n",
    "ax2.set_title('5 different function realizations from posterior')\n",
    "ax1.axis([domain[0], domain[1], -3, 3])\n",
    "ax2.set_xlim([-6, 6])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
